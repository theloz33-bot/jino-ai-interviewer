import streamlit as st
import os
import json
import uuid
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate

# ==========================================
# 1. Schemas & Config
# ==========================================
class Settings(BaseModel):
    max_questions: int = 5
    difficulty: str = "medium"

class State(BaseModel):
    phase: str = "interview"
    current_q_index: int = 0
    followup_used_for_current_q: bool = False
    completed: bool = False

class InterviewerOutput(BaseModel):
    type: str
    prompt: Dict[str, str]
    q_index: int
    category: str

class EvaluationOutput(BaseModel):
    report_markdown: Dict[str, str]

class QAItem(BaseModel):
    q_index: int
    category: str
    question: Dict[str, str]
    answer: str = ""
    followup: Optional[Dict[str, Any]] = None

class InterviewSession(BaseModel):
    session_id: str
    user_id: str
    settings: Settings = Field(default_factory=Settings)
    state: State = Field(default_factory=State)
    qa_log: List[Dict[str, Any]] = Field(default_factory=list)

class OrchestratorResponse(BaseModel):
    session: InterviewSession
    output: Any

# ==========================================
# 2. Prompts
# ==========================================
INTERVIEWER_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ íƒœì–‘ê´‘ ì¸ë²„í„° ê¸°ìˆ ì˜ì—… ì§ë¬´ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ì§€ì›ìëŠ” í•œêµ­ì¸ì´ë©°, ë² íŠ¸ë‚¨ ì‹œì¥ ì§„ì¶œì„ ëª©í‘œë¡œ í•˜ëŠ” íšŒì‚¬ì˜ ì˜ì—… ë‹´ë‹¹ì í›„ë³´ì…ë‹ˆë‹¤.
í˜„ì¬ ë©´ì ‘ ì§„í–‰ ìƒí™©ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

[ë©´ì ‘ ì„¤ì •]
- ì´ ì§ˆë¬¸ ìˆ˜: {max_questions}
- í˜„ì¬ ì§ˆë¬¸ ìˆœì„œ: {current_q_index}ë²ˆì§¸ ì§ˆë¬¸ (ì´ì œ ìƒì„±í•´ì•¼ í•¨)

[ì´ì „ ëŒ€í™” ê¸°ë¡]
{qa_history}

[ë§ˆì§€ë§‰ ë‹µë³€]
{last_answer}

[ì§€ì‹œì‚¬í•­]
1. ê¼¬ë¦¬ì§ˆë¬¸ ìš”ì²­(Follow-up Request)ì´ "YES"ë¼ë©´, ë§ˆì§€ë§‰ ë‹µë³€ì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ íŒŒê³ ë“œëŠ” ê¼¬ë¦¬ì§ˆë¬¸ì„ í•˜ì„¸ìš”.
2. "NO"ë¼ë©´, ë‹¤ìŒ ì£¼ì œë¡œ ë„˜ì–´ê°€ì„œ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ í•˜ì„¸ìš”.
3. ì§ˆë¬¸ì€ ë°˜ë“œì‹œ **í•œêµ­ì–´(ko)**ì™€ **ë² íŠ¸ë‚¨ì–´(vi)** ë‘ ê°€ì§€ë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
4. ì§ˆë¬¸ì˜ ì˜ë„(Category)ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
5. ì¶œë ¥ì€ ë°˜ë“œì‹œ **JSON í¬ë§·**ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

[JSON ì¶œë ¥ ì˜ˆì‹œ]
{{
  "type": "question",  // ë˜ëŠ” "followup"
  "q_index": {current_q_index},
  "category": "ì§ë¬´ ì í•©ì„±",
  "prompt": {{
    "ko": "ë² íŠ¸ë‚¨ ì‹œì¥ì—ì„œ ìš°ë¦¬ íšŒì‚¬ì˜ ì¸ë²„í„°ê°€ ê²½ìŸì‚¬ ëŒ€ë¹„ ì–´ë–¤ ê°•ì ì„ ê°€ì§ˆ ìˆ˜ ìˆë‹¤ê³  ìƒê°í•˜ì‹œë‚˜ìš”?",
    "vi": "Theo báº¡n, biáº¿n táº§n cá»§a cÃ´ng ty chÃºng tÃ´i cÃ³ nhá»¯ng Ä‘iá»ƒm máº¡nh gÃ¬ so vá»›i Ä‘á»‘i thá»§ cáº¡nh tranh táº¡i thá»‹ trÆ°á»ng Viá»‡t Nam?"
  }}
}}

Follow-up Request: {followup_request}
JSON Output:
"""

EVALUATOR_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ ë©´ì ‘ í‰ê°€ê´€ì…ë‹ˆë‹¤. ì•„ë˜ ë©´ì ‘ ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.

[ë©´ì ‘ ê¸°ë¡]
{qa_history}

[í‰ê°€ ê¸°ì¤€]
1. ì§ë¬´ ì´í•´ë„ (íƒœì–‘ê´‘ ì¸ë²„í„°, ê¸°ìˆ ì˜ì—…)
2. ë¬¸ì œ í•´ê²° ëŠ¥ë ¥
3. ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ (ë…¼ë¦¬ì„±)
4. íƒœë„ ë° ì—´ì •

[ì¶œë ¥ í˜•ì‹]
ë°˜ë“œì‹œ **JSON í¬ë§·**ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
{{
  "report_markdown": {{
    "ko": "# ë©´ì ‘ í‰ê°€ ë¦¬í¬íŠ¸\\n\\n## 1. ì´í‰\\n...\\n\\n## 2. í•­ëª©ë³„ ì ìˆ˜\\n- ì§ë¬´ ì´í•´ë„: 80/100\\n...",
    "vi": "..."
  }}
}}

JSON Output:
"""

# ==========================================
# 3. Agents
# ==========================================
class InterviewerAgent:
    def __init__(self):
        # API Key ì§ì ‘ ì£¼ì… (ì‚¬ìš©ì ì œê³µ)
        api_key = "AIzaSyDwZsm-JRXLdwCocXGVVdKRfld5m5dC-TQ"
        if not os.environ.get("GOOGLE_API_KEY"):
            os.environ["GOOGLE_API_KEY"] = api_key

        self.llm = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.7)
        self.prompt_template = PromptTemplate(
            input_variables=["current_q_index", "max_questions", "qa_history", "last_answer", "followup_request"],
            template=INTERVIEWER_PROMPT_TEMPLATE
        )

    def generate_question(self, session_data, is_followup: bool = False) -> InterviewerOutput:
        state = session_data.state
        qa_log = session_data.qa_log
        settings = session_data.settings

        history_text = ""
        for item in qa_log:
            q_idx = item.get("q_index") if isinstance(item, dict) else item.q_index
            question = item.get("question") if isinstance(item, dict) else item.question
            answer = item.get("answer", "") if isinstance(item, dict) else item.answer
            history_text += f"Q{q_idx}: {question['ko']}\nA: {answer}\n"
            
            followup = item.get("followup") if isinstance(item, dict) else getattr(item, "followup", None)
            if followup and followup.get("asked"):
                history_text += f"  (Follow-up Q): {followup['question']['ko']}\n  (Follow-up A): {followup.get('answer', '')}\n"

        last_answer = ""
        if qa_log:
             last_qa = qa_log[-1]
             l_answer = last_qa.get("answer", "") if isinstance(last_qa, dict) else last_qa.answer
             l_followup = last_qa.get("followup") if isinstance(last_qa, dict) else getattr(last_qa, "followup", None)
             
             if is_followup: 
                 last_answer = l_answer
             elif l_followup and l_followup.get("answer"):
                 last_answer = l_followup["answer"]
             else:
                 last_answer = l_answer

        final_prompt = self.prompt_template.format(
            current_q_index=state.current_q_index,
            max_questions=settings.max_questions,
            qa_history=history_text,
            last_answer=last_answer,
            followup_request="YES" if is_followup else "NO"
        )
        
        try:
            response = self.llm.invoke(final_prompt)
            content = response.content
            cleaned_content = content.strip()
            if cleaned_content.startswith("```"):
                lines = cleaned_content.splitlines()
                if lines[0].strip().startswith("```"): lines = lines[1:]
                if lines[-1].strip().startswith("```"): lines = lines[:-1]
                cleaned_content = "\n".join(lines)
            data = json.loads(cleaned_content)
            return InterviewerOutput(
                type=data.get("type", "question"),
                prompt=data.get("prompt", {"ko": "ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜", "vi": "Lá»—i táº¡o cÃ¢u há»i"}),
                q_index=data.get("q_index", state.current_q_index),
                category=data.get("category", "General")
            )
        except Exception as e:
            return InterviewerOutput(
                type="error",
                prompt={"ko": "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "vi": "Error"},
                q_index=state.current_q_index,
                category="Error"
            )

class EvaluatorAgent:
    def __init__(self):
        # API Key ì§ì ‘ ì£¼ì…
        api_key = "AIzaSyDwZsm-JRXLdwCocXGVVdKRfld5m5dC-TQ"
        if not os.environ.get("GOOGLE_API_KEY"):
            os.environ["GOOGLE_API_KEY"] = api_key

        self.llm = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.7)
        self.prompt_template = PromptTemplate(
            input_variables=["qa_history"],
            template=EVALUATOR_PROMPT_TEMPLATE
        )

    def evaluate_interview(self, session_data) -> EvaluationOutput:
        qa_log = session_data.qa_log
        history_text = ""
        for item in qa_log:
            q_idx = item.get("q_index") if isinstance(item, dict) else item.q_index
            question = item.get("question") if isinstance(item, dict) else item.question
            answer = item.get("answer", "") if isinstance(item, dict) else item.answer
            history_text += f"Q{q_idx}: {question['ko']}\nA: {answer}\n"
            
            followup = item.get("followup") if isinstance(item, dict) else getattr(item, "followup", None)
            if followup and followup.get("asked"):
                history_text += f"  (Follow-up Q): {followup['question']['ko']}\n  (Follow-up A): {followup.get('answer', '')}\n"
        
        final_prompt = self.prompt_template.format(qa_history=history_text)
        
        try:
            response = self.llm.invoke(final_prompt)
            content = response.content
            cleaned_content = content.strip()
            if cleaned_content.startswith("```"):
                lines = cleaned_content.splitlines()
                if lines[0].strip().startswith("```"): lines = lines[1:]
                if lines[-1].strip().startswith("```"): lines = lines[:-1]
                cleaned_content = "\n".join(lines)
            data = json.loads(cleaned_content)
            return EvaluationOutput(
                report_markdown=data.get("report_markdown", {"ko": "í‰ê°€ ì‹¤íŒ¨", "vi": "Fail"})
            )
        except Exception:
            return EvaluationOutput(report_markdown={"ko": "ì˜¤ë¥˜ ë°œìƒ", "vi": "Error"})

# ==========================================
# 4. Session Manager
# ==========================================
class SessionManager:
    def __init__(self):
        if "sessions" not in st.session_state:
            st.session_state.sessions = {}
        self.sessions = st.session_state.sessions

    def create_new_session(self, user_id: str) -> InterviewSession:
        session_id = str(uuid.uuid4())
        new_session = InterviewSession(session_id=session_id, user_id=user_id)
        self.sessions[session_id] = new_session
        return new_session

    def get_session(self, session_id: str) -> Optional[InterviewSession]:
        return self.sessions.get(session_id)

    def save_session(self, session: InterviewSession):
        self.sessions[session.session_id] = session

# ==========================================
# 5. Orchestrator
# ==========================================
class Orchestrator:
    def __init__(self, session_manager, interviewer_agent: InterviewerAgent, evaluator_agent: EvaluatorAgent):
        self.session_manager = session_manager
        self.interviewer = interviewer_agent
        self.evaluator = evaluator_agent

    def process_message(self, session_id: str, user_message: str) -> Optional[OrchestratorResponse]:
        session = self.session_manager.get_session(session_id)
        if not session: return None

        # 1. Start
        if user_message == "" and not session.qa_log:
            output = self.interviewer.generate_question(session, is_followup=False)
            new_qa = {"q_index": output.q_index, "category": output.category, "question": output.prompt, "answer": "", "followup": None}
            session.qa_log.append(new_qa)
            session.state.current_q_index = output.q_index
            self.session_manager.save_session(session)
            return OrchestratorResponse(session=session, output=output)

        # 2. Answer
        last_qa = session.qa_log[-1]
        if last_qa.get("followup") and last_qa["followup"].get("asked") and not last_qa["followup"].get("answer"):
             last_qa["followup"]["answer"] = user_message
             session.state.followup_used_for_current_q = False 
             session.state.current_q_index += 1
        else:
             last_qa["answer"] = user_message
             is_ambiguous = len(user_message) < 10 and len(user_message) > 0
             need_followup = False
             if is_ambiguous and not session.state.followup_used_for_current_q:
                 need_followup = True
                 session.state.followup_used_for_current_q = True
             else:
                 session.state.current_q_index += 1
                 session.state.followup_used_for_current_q = False

        # 3. End
        if session.state.current_q_index > session.settings.max_questions:
            if not session.state.followup_used_for_current_q:
                session.state.phase = "evaluation"
                return self._run_evaluation(session)

        # 4. Next Question
        is_followup_needed = session.state.followup_used_for_current_q
        output = self.interviewer.generate_question(session_data=session, is_followup=is_followup_needed)
        
        if is_followup_needed:
            if session.qa_log:
                session.qa_log[-1]["followup"] = {"question": output.prompt, "answer": "", "asked": True}
        else:
            if session.state.phase != "evaluation":
                new_qa = {"q_index": output.q_index, "category": output.category, "question": output.prompt, "answer": "", "followup": None}
                session.qa_log.append(new_qa)
            
        self.session_manager.save_session(session)
        return OrchestratorResponse(session=session, output=output)

    def _run_evaluation(self, session: InterviewSession) -> OrchestratorResponse:
        output = self.evaluator.evaluate_interview(session)
        session.state.phase = "done"
        session.state.completed = True
        self.session_manager.save_session(session)
        return OrchestratorResponse(session=session, output=output)

# ==========================================
# 6. Streamlit App UI
# ==========================================
load_dotenv()
st.set_page_config(page_title="AI ë©´ì ‘ê´€", layout="wide")

def init_session():
    if "session_manager" not in st.session_state:
        st.session_state.session_manager = SessionManager()
        st.session_state.interviewer = InterviewerAgent()
        st.session_state.evaluator = EvaluatorAgent()
        st.session_state.orchestrator = Orchestrator(
            st.session_state.session_manager,
            st.session_state.interviewer,
            st.session_state.evaluator
        )
    if "messages" not in st.session_state:
        st.session_state.messages = []

init_session()

st.title("â˜€ï¸ íƒœì–‘ê´‘ ì¸ë²„í„° ê¸°ìˆ ì˜ì—… - AI ë©´ì ‘")

with st.sidebar:
    if st.button("ğŸ”„ ì´ˆê¸°í™”"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

if "current_session_id" not in st.session_state:
    st.info("ğŸ‘‡ ë©´ì ‘ì„ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ì…ë ¥ì°½ì— 'ì‹œì‘'ì„ ì…ë ¥í•˜ê³  ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
    start_input = st.text_input("ì…ë ¥:", value="", key="start_input")
    if start_input:
        with st.spinner("ë©´ì ‘ê´€ ì¤€ë¹„ ì¤‘..."):
            new_session = st.session_state.session_manager.create_new_session("user1")
            st.session_state.current_session_id = new_session.session_id
            st.session_state.messages = []
            response = st.session_state.orchestrator.process_message(new_session.session_id, "")
            if response:
                output = response.output
                bot_msg = f"**[Q{output.q_index}] {output.prompt['ko']}**\n\n_{output.prompt['vi']}_"
                st.session_state.messages.append({"role": "assistant", "content": bot_msg})
        st.rerun()
else:
    for msg in st.session_state.messages:
        role = "ğŸ¤– ë©´ì ‘ê´€" if msg["role"] == "assistant" else "ğŸ‘¤ ì§€ì›ì"
        st.markdown(f"**{role}:**")
        st.markdown(msg["content"])
        st.markdown("---")

    user_input = st.text_input("ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”:", key="user_answer_input")
    if user_input:
        if not st.session_state.messages or st.session_state.messages[-1]["content"] != user_input:
            st.session_state.messages.append({"role": "user", "content": user_input})
            with st.spinner("ìƒê° ì¤‘..."):
                response = st.session_state.orchestrator.process_message(
                    st.session_state.current_session_id, 
                    user_input
                )
            if response:
                output = response.output
                if output.type in ["question", "followup"]:
                    bot_msg = f"**[Q{output.q_index}] {output.prompt['ko']}**\n\n_{output.prompt['vi']}_"
                    st.session_state.messages.append({"role": "assistant", "content": bot_msg})
                elif hasattr(output, "report_markdown"):
                    st.success("ë©´ì ‘ ì¢…ë£Œ!")
                    report = output.report_markdown["ko"]
                    st.session_state.messages.append({"role": "assistant", "content": report})
            st.rerun()
